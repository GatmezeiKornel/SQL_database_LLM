{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from pprint import pprint\n",
    "from utils.prompts.prompt import *\n",
    "from utils.prompts.Schema_Prompt_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_score(logprobs: list) -> float:\n",
    "    probs = []\n",
    "    # iterate through the token predictions and get the linear probs [0;1]\n",
    "    for logprob in logprobs:\n",
    "        probs.append(np.round(np.exp(logprob)*100, 2))\n",
    "    # calculate the confidence\n",
    "    return round(np.mean(probs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key = \"823ee8f13b594481a9c23dbb62a60fb8\",\n",
    "    api_version = \"2024-03-01-preview\",\n",
    "    azure_endpoint = \"https://sql-chat-agent.openai.azure.com/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"Forgalomban van a novocetrin?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_gen_messages = [\n",
    "                {\"role\": \"system\", \"content\" : sql_system_message.format(system_prompt=SQL_SYSTEM_PROMPT, \n",
    "                                                                    table_info=SCHEMA_PROMPT)},\n",
    "                {\"role\": \"user\", \"content\": question_message.format(question=QUERY)}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"SELECT TOP 10 * FROM GYOGYSZ WHERE OEP_NEV LIKE '%novocetrin%' AND \"\n",
      " 'FORGALOMBAN = 1')\n"
     ]
    }
   ],
   "source": [
    "full_response = client.chat.completions.create(\n",
    "    model=\"TextToSql_Pupha\",\n",
    "    messages=sql_gen_messages,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024,\n",
    "    logprobs=True\n",
    ")\n",
    "pprint(full_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9EwUhJqFHDRXiCRAFiqZ9G4jNaRGx', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='SELECT', bytes=[83, 69, 76, 69, 67, 84], logprob=-0.0049804244, top_logprobs=[]), ChatCompletionTokenLogprob(token=' TOP', bytes=[32, 84, 79, 80], logprob=-0.55307436, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00089180964, top_logprobs=[]), ChatCompletionTokenLogprob(token='10', bytes=[49, 48], logprob=-1.50940705e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' *', bytes=[32, 42], logprob=-0.16820113, top_logprobs=[]), ChatCompletionTokenLogprob(token=' FROM', bytes=[32, 70, 82, 79, 77], logprob=-0.009937405, top_logprobs=[]), ChatCompletionTokenLogprob(token=' G', bytes=[32, 71], logprob=-0.00095362135, top_logprobs=[]), ChatCompletionTokenLogprob(token='Y', bytes=[89], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='OG', bytes=[79, 71], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='YS', bytes=[89, 83], logprob=-2.6968896e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='Z', bytes=[90], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' WHERE', bytes=[32, 87, 72, 69, 82, 69], logprob=-0.00017171667, top_logprobs=[]), ChatCompletionTokenLogprob(token=' O', bytes=[32, 79], logprob=-0.73134756, top_logprobs=[]), ChatCompletionTokenLogprob(token='EP', bytes=[69, 80], logprob=-5.276243e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='_NE', bytes=[95, 78, 69], logprob=-2.7372049e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='V', bytes=[86], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' LIKE', bytes=[32, 76, 73, 75, 69], logprob=-0.46047685, top_logprobs=[]), ChatCompletionTokenLogprob(token=\" '%\", bytes=[32, 39, 37], logprob=-0.02551935, top_logprobs=[]), ChatCompletionTokenLogprob(token='nov', bytes=[110, 111, 118], logprob=-0.008136622, top_logprobs=[]), ChatCompletionTokenLogprob(token='oc', bytes=[111, 99], logprob=-7.226629e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='etr', bytes=[101, 116, 114], logprob=-0.00019436171, top_logprobs=[]), ChatCompletionTokenLogprob(token='in', bytes=[105, 110], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"%'\", bytes=[37, 39], logprob=-0.0003390383, top_logprobs=[]), ChatCompletionTokenLogprob(token=' AND', bytes=[32, 65, 78, 68], logprob=-0.00019126241, top_logprobs=[]), ChatCompletionTokenLogprob(token=' FOR', bytes=[32, 70, 79, 82], logprob=-7.9418505e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='G', bytes=[71], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='AL', bytes=[65, 76], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='OMB', bytes=[79, 77, 66], logprob=-6.511407e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='AN', bytes=[65, 78], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0006965888, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-2.749125e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='1', bytes=[49], logprob=0.0, top_logprobs=[])]), message=ChatCompletionMessage(content=\"SELECT TOP 10 * FROM GYOGYSZ WHERE OEP_NEV LIKE '%novocetrin%' AND FORGALOMBAN = 1\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1713348471, model='gpt-4', object='chat.completion', system_fingerprint='fp_8abb16fa4e', usage=CompletionUsage(completion_tokens=32, prompt_tokens=5817, total_tokens=5849), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "pprint(full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs = [x.logprob for x in full_response.choices[0].logprobs.content]\n",
    "calculate_confidence_score(logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
